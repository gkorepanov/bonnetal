# training parameters
train:
  loss: "xentropy"       # must be either xentropy or iou
  max_epochs: 10000
  max_lr: 0.01           # sgd learning rate max
  min_lr: 0.001          # warmup initial learning rate
  up_epochs: 0.3         # warmup during first XX epochs (can be float)
  down_epochs:  100      # warmdown during second XX epochs  (can be float)
  max_momentum: 0.9      # sgd momentum max when lr is mim
  min_momentum: 0.85     # sgd momentum min when lr is max
  final_decay: 0.995     # learning rate decay per epoch after initial cycle (from min lr)
  w_decay: 0.0005        # weight decay
  batch_size: 48         # batch size
  report_batch: 1        # every x batches, report loss
  report_epoch: 1        # every x epochs, report validation set
  save_summary: False    # Summary of weight histograms for tensorboard
  save_imgs: True        # False doesn't save anything, True saves some
  num_images_to_save: 15
  avg_N: 3               # average the N best models
  training_mode: "temporal_loss_mask_prop"
  temporal_loss_strength: 0.6
  prev_gt_loss_strength: 1.0
  input_size: [288, 512, 3]
  scheduler: "oneshot"

# backbone parameters
backbone:
  name: "mobilenetv2"
  dropout: 0.02
  bn_d: 0.05
  OS: 16 # output stride
  train: True # train backbone?
  extra:
    width_mult: 1.0
    shallow_feats: True # get features before the last layer (mn2)
    aggressive_downsample: True
    prune_last_layer: True
    use_prev_mask: False

decoder:
  name: "aspp_progressive"
  dropout: 0.02
  bn_d: 0.05
  train: True # train decoder?
  extra:
    aspp_channels: 32
    last_channels: 16
    ASPP_rates: [4, 8, 12]  # 18 x 32 map

# classification head parameters
head:
  name: "segmentation"
  dropout: 0.1

# dataset (to find parser)
dataset:
  name: "persons_augmented_v3"
  train_datasets:
#     - location: /home/g-korepanov/datasets/nvidia_processed/train
#       name: "folder"
#       scale: [0.2, 0.5]
#       baseline_augmenter: random_crop_spoil
#       extra:
#         ignore_files: []
#     - location: /home/g-korepanov/datasets/supervisely_processed/train
#       name: "folder"
#       scale: [0.5, 2.0]
#       baseline_augmenter: random_crop_spoil
#       extra:
#         ignore_files: []
    - location: /home/g-korepanov/datasets/coco
      name: "coco"
      scale: [0.5, 2.0]
      baseline_augmenter: random_crop_spoil
      extra:
        is_train: True
  valid_datasets:
#     - location: /home/g-korepanov/datasets/nvidia_processed/valid
#       name: "folder"
#       scale: [0.2, 0.5]
#       baseline_augmenter: random_crop_spoil
#       extra:
#         ignore_files: []
#     - location: /home/g-korepanov/datasets/supervisely_processed/valid
#       name: "folder"
#       scale: [0.5, 2.0]
#       baseline_augmenter: random_crop_spoil
#       extra:
#         ignore_files: []
    - location: /home/g-korepanov/datasets/coco
      name: "coco"
      scale: [0.5, 2.0]
      baseline_augmenter: random_crop_spoil
      extra:
        is_train: False
  test_datasets:
    - location: /home/g-korepanov/datasets/web_crop
      name: "folder"
      baseline_augmenter: resize
      extra:
        ignore_files: ['35.png', '105.png', '118.png', '130.png', '318.png', '317.png', '319.png', '323.png', '289.png', '290.png', '283.png', '157.png', '246.png', '190.png', '305.png', '38.png', '133.png', '153.png', '156.png', '164.png', '177.png', '175.png', '173.png', '172.png', '174.png', '180.png', '170.png', '178.png', '182.png', '179.png', '181.png', '63.png', '169.png', '171.png', '176.png', '142.png', '93.png', '204.png']
  num_workers: 10 # number of threads to get data
  crop_prop:
    height: 288
    width: 512
  img_means: # rgb
    - 0.46992042
    - 0.45250652
    - 0.42510188
  img_stds: # rgb
    - 0.29184756
    - 0.28221624
    - 0.29719201
  labels:
    0: 'background'
    1: 'person'
  labels_w:
    0: 1.0
    1: 1.0
  color_map: # bgr
    0: [0,0,0]
    1: [0,255,0]
    -1: [255,0,0]
  curr2prev_optical_flow_generator: "imgaug_affine_elastic_large"
  prev_image_generator: "optical_flow_and_local"
  prev_mask_generator: "optical_flow"
